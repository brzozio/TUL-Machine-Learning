{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "base_path : str = os.path.dirname(os.getcwd())\n",
    "CSV_PATH  : str = base_path + '\\\\csv'\n",
    "SRC_PATH  : str = base_path + '\\\\src'\n",
    "JSON_PATH : str = base_path + '\\\\json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>RATED</th>\n",
       "      <th>NAN_RATED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>{'1': 2.0, '4': 2.0, '6': 3.0, '8': 4.0, '12':...</td>\n",
       "      <td>{'0': -1.0, '2': -1.0, '3': -1.0, '5': -1.0, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>{'2': 2.0, '3': 5.0, '5': 4.0, '9': 1.0, '10':...</td>\n",
       "      <td>{'0': -1.0, '1': -1.0, '4': -1.0, '6': -1.0, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>{'0': 5.0, '1': 2.0, '5': 2.0, '6': 5.0, '10':...</td>\n",
       "      <td>{'2': -1.0, '3': -1.0, '4': -1.0, '7': -1.0, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>{'1': 5.0, '4': 5.0, '5': 5.0, '6': 5.0, '8': ...</td>\n",
       "      <td>{'0': -1.0, '2': -1.0, '3': -1.0, '7': -1.0, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>{'1': 0.0, '6': 3.0, '7': 1.0, '10': 0.0, '11'...</td>\n",
       "      <td>{'0': -1.0, '2': -1.0, '3': -1.0, '4': -1.0, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>1796</td>\n",
       "      <td>{'0': 3.0, '1': 1.0, '3': 3.0, '6': 0.0, '7': ...</td>\n",
       "      <td>{'2': -1.0, '4': -1.0, '5': -1.0, '8': -1.0, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1804</td>\n",
       "      <td>{'1': 3.0, '2': 2.0, '3': 4.0, '9': 3.0, '10':...</td>\n",
       "      <td>{'0': -1.0, '4': -1.0, '5': -1.0, '6': -1.0, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1813</td>\n",
       "      <td>{'0': 3.0, '1': 5.0, '2': 5.0, '4': 3.0, '5': ...</td>\n",
       "      <td>{'3': -1.0, '7': -1.0, '8': -1.0, '9': -1.0, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>1815</td>\n",
       "      <td>{'2': 4.0, '3': 3.0, '4': 2.0, '5': 1.0, '48':...</td>\n",
       "      <td>{'0': -1.0, '1': -1.0, '6': -1.0, '7': -1.0, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>1816</td>\n",
       "      <td>{'0': 2.0, '2': 2.0, '3': 4.0, '6': 4.0, '7': ...</td>\n",
       "      <td>{'1': -1.0, '4': -1.0, '5': -1.0, '9': -1.0, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     USER_ID                                              RATED  \\\n",
       "0          5  {'1': 2.0, '4': 2.0, '6': 3.0, '8': 4.0, '12':...   \n",
       "1         12  {'2': 2.0, '3': 5.0, '5': 4.0, '9': 1.0, '10':...   \n",
       "2         19  {'0': 5.0, '1': 2.0, '5': 2.0, '6': 5.0, '10':...   \n",
       "3         24  {'1': 5.0, '4': 5.0, '5': 5.0, '6': 5.0, '8': ...   \n",
       "4         31  {'1': 0.0, '6': 3.0, '7': 1.0, '10': 0.0, '11'...   \n",
       "..       ...                                                ...   \n",
       "353     1796  {'0': 3.0, '1': 1.0, '3': 3.0, '6': 0.0, '7': ...   \n",
       "354     1804  {'1': 3.0, '2': 2.0, '3': 4.0, '9': 3.0, '10':...   \n",
       "355     1813  {'0': 3.0, '1': 5.0, '2': 5.0, '4': 3.0, '5': ...   \n",
       "356     1815  {'2': 4.0, '3': 3.0, '4': 2.0, '5': 1.0, '48':...   \n",
       "357     1816  {'0': 2.0, '2': 2.0, '3': 4.0, '6': 4.0, '7': ...   \n",
       "\n",
       "                                             NAN_RATED  \n",
       "0    {'0': -1.0, '2': -1.0, '3': -1.0, '5': -1.0, '...  \n",
       "1    {'0': -1.0, '1': -1.0, '4': -1.0, '6': -1.0, '...  \n",
       "2    {'2': -1.0, '3': -1.0, '4': -1.0, '7': -1.0, '...  \n",
       "3    {'0': -1.0, '2': -1.0, '3': -1.0, '7': -1.0, '...  \n",
       "4    {'0': -1.0, '2': -1.0, '3': -1.0, '4': -1.0, '...  \n",
       "..                                                 ...  \n",
       "353  {'2': -1.0, '4': -1.0, '5': -1.0, '8': -1.0, '...  \n",
       "354  {'0': -1.0, '4': -1.0, '5': -1.0, '6': -1.0, '...  \n",
       "355  {'3': -1.0, '7': -1.0, '8': -1.0, '9': -1.0, '...  \n",
       "356  {'0': -1.0, '1': -1.0, '6': -1.0, '7': -1.0, '...  \n",
       "357  {'1': -1.0, '4': -1.0, '5': -1.0, '9': -1.0, '...  \n",
       "\n",
       "[358 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rating = pd.read_json(JSON_PATH + r'\\USER_RATING_DATA.json')\n",
    "user_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_distance = pd.read_json(JSON_PATH + r'\\movie_distance_graph.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weight_samples(num_samples=10000, weight_count=5, min_val=0.5, max_val=1.1, sum_constraint=None):\n",
    "    import random\n",
    "    samples = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        if sum_constraint is not None:\n",
    "            # Generate weights that satisfy the sum constraint\n",
    "            weights = []\n",
    "            for _ in range(weight_count):\n",
    "                weight = random.uniform(min_val, max_val)\n",
    "                weights.append(weight)\n",
    "            \n",
    "            # Normalize to meet the sum constraint\n",
    "            current_sum = sum(weights)\n",
    "            if current_sum != 0:  # Avoid division by zero\n",
    "                weights = [w * (sum_constraint / current_sum) for w in weights]\n",
    "            \n",
    "            # Clamp values to ensure they are within range after normalization\n",
    "            weights = [max(min(w, max_val), min_val) for w in weights]\n",
    "        else:\n",
    "            # Generate weights freely within the range\n",
    "            weights = [random.uniform(min_val, max_val) for _ in range(weight_count)]\n",
    "        \n",
    "        samples.append(weights)\n",
    "    \n",
    "    return samples\n",
    "\n",
    "PARAMS_WEIGHTS = generate_weight_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(movie_id, all_distances, training_ids, rating_data, threshold) -> int:\n",
    "\n",
    "    \"\"\"\n",
    "        Dla movie_id wyszukujemyt filmy, które oddalone są od movie_id o mniej niż THRESHOLD.\n",
    "        Jeśli taki jest, to zapamiętujemy jego ocenę, a potem ze wszystkich wyciątgamy średnią.\n",
    "    \"\"\"\n",
    "    \n",
    "    decisions: list = []\n",
    "\n",
    "    for rated_movie in training_ids:\n",
    "\n",
    "        feature_counter: int = 0\n",
    "\n",
    "        for feat_dist_i, feature_distance in enumerate(all_distances[movie_id][int(rated_movie)]):\n",
    "\n",
    "            if feature_distance < threshold[feat_dist_i]:\n",
    "\n",
    "                feature_counter += 1\n",
    "\n",
    "        if feature_counter == 5:\n",
    "\n",
    "            decisions.append(rating_data[str(rated_movie)])\n",
    "\n",
    "\n",
    "    return np.ceil(np.average(decisions)) if len(decisions) > 0 else None\n",
    "\n",
    "def optimize_user(user, validate_ids, training_ids) -> tuple[float, list]:\n",
    "\n",
    "    max_accuracy: float = -1.0\n",
    "    best_weights: list = []\n",
    "\n",
    "    for weights in PARAMS_WEIGHTS:\n",
    "\n",
    "        accuracy: float = 0.0\n",
    "\n",
    "        for validate_movie in validate_ids:\n",
    "\n",
    "            # output = decision_tree(movie_id=validate_movie, all_distances=movie_distance, training_ids=training_ids, rating_data={k: v for k, v in user_rating[\"RATED\"][user].items() if int(k) in [training_ids+validate_ids]}, threshold=weights)\n",
    "            output = decision_tree(movie_id=validate_movie, all_distances=movie_distance, training_ids=training_ids, rating_data=user_rating[\"RATED\"][user], threshold=weights)\n",
    "\n",
    "            # print(f\"Output: {output}, True value: {user_rating['RATED'][user][str(validate_movie)]}\")\n",
    "\n",
    "            if output is not None and output == user_rating['RATED'][user][str(validate_movie)]:\n",
    "                accuracy += 1.0\n",
    "        \n",
    "        accuracy = accuracy/len(validate_ids)\n",
    "\n",
    "        if accuracy > max_accuracy:\n",
    "\n",
    "            max_accuracy = accuracy\n",
    "            best_weights = weights\n",
    "    \n",
    "    return (max_accuracy, best_weights)\n",
    "\n",
    "def test_user(user_id, best_weights, test_ids, train_ids) -> float:\n",
    "\n",
    "    accuracy: float = 0.0\n",
    "\n",
    "    for test_movie in test_ids:\n",
    "\n",
    "        # output = decision_tree(movie_id=validate_movie, all_distances=movie_distance, training_ids=training_ids, rating_data={k: v for k, v in user_rating[\"RATED\"][user].items() if int(k) in [training_ids+validate_ids]}, threshold=weights)\n",
    "        output = decision_tree(movie_id=test_movie, all_distances=movie_distance, training_ids=train_ids, rating_data=user_rating[\"RATED\"][user_id], threshold=best_weights)\n",
    "\n",
    "        if output is not None and output == user_rating['RATED'][user_id][str(test_movie)]:\n",
    "            accuracy += 1.0\n",
    "    \n",
    "    accuracy = accuracy/len(test_ids)\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:41: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:41: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "C:\\Users\\Michał\\AppData\\Local\\Temp\\ipykernel_16520\\3889676930.py:41: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  print(f\"{user}. User: {user_rating['USER_ID'][user]} weights are: {best_weights_out} with appx accuracy of {accuracy:.2f}\") if accuracy is not 0 else print(f\"{user}. {user_rating['USER_ID'][user]} has accuracy of 0!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. User: 5 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 1.00\n",
      "1. User: 12 weights are: [0.8729297191323443, 0.9522857769513937, 1.041023810723141, 0.9726753165162894, 0.8876427606071381] with appx accuracy of 0.56\n",
      "2. User: 19 weights are: [0.8473264616587173, 1.0019951001263538, 1.0411707095092373, 1.0929873771653644, 0.6622237626119192] with appx accuracy of 0.33\n",
      "3. User: 24 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.89\n",
      "4. User: 31 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.11\n",
      "5. User: 52 weights are: [1.0643049885274403, 0.5727147218047988, 1.0674307555964493, 1.0790417212099985, 1.0665195983007454] with appx accuracy of 0.67\n",
      "6. User: 62 weights are: [0.6691426121972595, 0.8263729392568, 1.0976472313745442, 0.9690412786869096, 1.0196008199789954] with appx accuracy of 0.22\n",
      "7. User: 63 weights are: [0.6691426121972595, 0.8263729392568, 1.0976472313745442, 0.9690412786869096, 1.0196008199789954] with appx accuracy of 0.22\n",
      "8. User: 68 weights are: [0.7309125186859506, 0.501475401007075, 1.0725345882838357, 1.0681284358550698, 0.5242808529647488] with appx accuracy of 0.56\n",
      "9. User: 69 weights are: [0.6691426121972595, 0.8263729392568, 1.0976472313745442, 0.9690412786869096, 1.0196008199789954] with appx accuracy of 0.56\n",
      "10. User: 70 weights are: [0.6415416517847025, 0.6382971746813249, 1.0711157263507884, 0.9560872450701314, 0.8844801318894199] with appx accuracy of 0.22\n",
      "11. User: 71 weights are: [0.6691426121972595, 0.8263729392568, 1.0976472313745442, 0.9690412786869096, 1.0196008199789954] with appx accuracy of 0.44\n",
      "12. User: 78 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.67\n",
      "13. User: 80 weights are: [0.6415416517847025, 0.6382971746813249, 1.0711157263507884, 0.9560872450701314, 0.8844801318894199] with appx accuracy of 0.22\n",
      "14. User: 90 weights are: [0.8646933484004478, 1.081397455083117, 1.0930596708782543, 1.038275953019249, 1.0521528534604674] with appx accuracy of 0.89\n",
      "15. User: 92 weights are: [0.7102806839095057, 0.6305263516230647, 1.060181947207255, 1.091779383271804, 0.6788749176966138] with appx accuracy of 0.33\n",
      "16. User: 93 weights are: [0.8646933484004478, 1.081397455083117, 1.0930596708782543, 1.038275953019249, 1.0521528534604674] with appx accuracy of 0.89\n",
      "17. User: 105 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.67\n",
      "18. User: 106 weights are: [0.6415416517847025, 0.6382971746813249, 1.0711157263507884, 0.9560872450701314, 0.8844801318894199] with appx accuracy of 0.44\n",
      "19. User: 109 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.56\n",
      "20. User: 118 weights are: [1.0835360415809743, 0.8354913993987441, 1.0198712331878548, 1.035192222136227, 0.936233911032374] with appx accuracy of 0.22\n",
      "21. User: 125 weights are: [0.6691426121972595, 0.8263729392568, 1.0976472313745442, 0.9690412786869096, 1.0196008199789954] with appx accuracy of 0.33\n",
      "22. User: 131 weights are: [0.9692470489511167, 0.8617681426985537, 0.7701780426833205, 1.09844922493399, 0.826933769121269] with appx accuracy of 0.33\n",
      "23. User: 139 weights are: [0.9315976501004086, 0.5485155292161954, 1.0033713131388757, 1.0900646825680318, 0.5078049429136513] with appx accuracy of 0.11\n",
      "24. User: 140 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.56\n",
      "25. User: 148 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.22\n",
      "26. User: 149 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.33\n",
      "27. User: 151 weights are: [0.6691426121972595, 0.8263729392568, 1.0976472313745442, 0.9690412786869096, 1.0196008199789954] with appx accuracy of 0.33\n",
      "28. User: 154 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.22\n",
      "29. User: 156 weights are: [0.5539699050937379, 0.7595239932619686, 1.0934626762722184, 1.0415095936498207, 0.5508829672179234] with appx accuracy of 0.56\n",
      "30. User: 165 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.22\n",
      "31. User: 169 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.78\n",
      "32. User: 175 weights are: [1.0927615892382787, 0.9866030365573971, 1.088038188031105, 1.0570913251024208, 0.7790453430245213] with appx accuracy of 0.33\n",
      "33. User: 176 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.22\n",
      "34. User: 180 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.22\n",
      "35. User: 181 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.44\n",
      "36. User: 183 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.67\n",
      "37. User: 188 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.22\n",
      "38. User: 189 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.44\n",
      "39. User: 196 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.22\n",
      "40. User: 207 weights are: [0.6691426121972595, 0.8263729392568, 1.0976472313745442, 0.9690412786869096, 1.0196008199789954] with appx accuracy of 0.33\n",
      "41. User: 210 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.22\n",
      "42. User: 233 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.89\n",
      "43. User: 235 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.44\n",
      "44. User: 239 weights are: [0.6420666464338849, 0.9417040349279078, 0.9261617276617613, 1.0374145469993323, 1.048100307015408] with appx accuracy of 0.56\n",
      "45. User: 240 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.44\n",
      "46. User: 251 weights are: [0.8646933484004478, 1.081397455083117, 1.0930596708782543, 1.038275953019249, 1.0521528534604674] with appx accuracy of 0.33\n",
      "47. User: 254 weights are: [1.0643049885274403, 0.5727147218047988, 1.0674307555964493, 1.0790417212099985, 1.0665195983007454] with appx accuracy of 0.33\n",
      "48. User: 258 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.56\n",
      "49. User: 265 weights are: [0.7102806839095057, 0.6305263516230647, 1.060181947207255, 1.091779383271804, 0.6788749176966138] with appx accuracy of 0.33\n",
      "50. User: 275 weights are: [0.9315976501004086, 0.5485155292161954, 1.0033713131388757, 1.0900646825680318, 0.5078049429136513] with appx accuracy of 0.33\n",
      "51. User: 279 weights are: [0.5311665318943372, 0.9973936399036505, 1.0055931812126644, 1.08242373322082, 1.032112916691509] with appx accuracy of 0.33\n",
      "52. User: 280 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.22\n",
      "53. User: 286 weights are: [0.5004482255847491, 0.5593566436973372, 1.0285720454484484, 1.0270631851832044, 0.7800504550691978] with appx accuracy of 0.67\n",
      "54. User: 292 weights are: [0.5549489261888239, 0.5420111348365156, 1.0145436818057003, 1.0060958322938653, 0.6220147605483326] with appx accuracy of 0.89\n",
      "55. User: 296 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.78\n",
      "56. User: 298 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 1.00\n",
      "57. User: 300 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.44\n",
      "58. User: 301 weights are: [0.5875538957629077, 0.5650106601813198, 1.0652298638746522, 1.07694581179036, 0.5970858968450601] with appx accuracy of 0.44\n",
      "59. User: 304 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.44\n",
      "60. User: 307 weights are: [0.6691426121972595, 0.8263729392568, 1.0976472313745442, 0.9690412786869096, 1.0196008199789954] with appx accuracy of 0.78\n",
      "61. User: 309 weights are: [0.8646933484004478, 1.081397455083117, 1.0930596708782543, 1.038275953019249, 1.0521528534604674] with appx accuracy of 0.44\n",
      "62. User: 314 weights are: [0.9315976501004086, 0.5485155292161954, 1.0033713131388757, 1.0900646825680318, 0.5078049429136513] with appx accuracy of 0.44\n",
      "63. User: 315 weights are: [0.9122949513731617, 0.5361354956005949, 1.088110869533586, 0.9810859426405536, 0.7642355510470096] with appx accuracy of 0.22\n",
      "64. User: 318 weights are: [0.5004482255847491, 0.5593566436973372, 1.0285720454484484, 1.0270631851832044, 0.7800504550691978] with appx accuracy of 0.33\n",
      "65. User: 327 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.33\n",
      "66. User: 331 weights are: [0.578855154982314, 0.672975825143737, 1.0523242776706123, 1.0125991691353775, 0.7959262119587887] with appx accuracy of 0.44\n",
      "67. User: 333 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.33\n",
      "68. User: 334 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.44\n",
      "69. User: 337 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.44\n",
      "70. User: 341 weights are: [0.5539699050937379, 0.7595239932619686, 1.0934626762722184, 1.0415095936498207, 0.5508829672179234] with appx accuracy of 0.56\n",
      "71. User: 343 weights are: [0.9692470489511167, 0.8617681426985537, 0.7701780426833205, 1.09844922493399, 0.826933769121269] with appx accuracy of 0.33\n",
      "72. User: 345 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.89\n",
      "73. User: 351 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.44\n",
      "74. User: 353 weights are: [0.6691426121972595, 0.8263729392568, 1.0976472313745442, 0.9690412786869096, 1.0196008199789954] with appx accuracy of 0.56\n",
      "75. User: 355 weights are: [0.8646933484004478, 1.081397455083117, 1.0930596708782543, 1.038275953019249, 1.0521528534604674] with appx accuracy of 1.00\n",
      "76. User: 365 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.56\n",
      "77. User: 370 weights are: [0.6415416517847025, 0.6382971746813249, 1.0711157263507884, 0.9560872450701314, 0.8844801318894199] with appx accuracy of 0.22\n",
      "78. User: 371 weights are: [0.7102806839095057, 0.6305263516230647, 1.060181947207255, 1.091779383271804, 0.6788749176966138] with appx accuracy of 0.22\n",
      "79. User: 381 weights are: [0.5004482255847491, 0.5593566436973372, 1.0285720454484484, 1.0270631851832044, 0.7800504550691978] with appx accuracy of 0.56\n",
      "80. User: 386 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.22\n",
      "81. User: 388 weights are: [0.6691426121972595, 0.8263729392568, 1.0976472313745442, 0.9690412786869096, 1.0196008199789954] with appx accuracy of 0.56\n",
      "82. User: 391 weights are: [0.6691426121972595, 0.8263729392568, 1.0976472313745442, 0.9690412786869096, 1.0196008199789954] with appx accuracy of 0.56\n",
      "83. User: 392 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.56\n",
      "84. User: 393 weights are: [0.6431838134917369, 0.5048950689080016, 1.0420781157197352, 1.0038795953435442, 0.7384801221042667] with appx accuracy of 0.44\n",
      "85. User: 395 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.22\n",
      "86. User: 398 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.44\n",
      "87. User: 407 weights are: [0.9315976501004086, 0.5485155292161954, 1.0033713131388757, 1.0900646825680318, 0.5078049429136513] with appx accuracy of 0.67\n",
      "88. User: 408 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.22\n",
      "89. User: 414 weights are: [0.5004482255847491, 0.5593566436973372, 1.0285720454484484, 1.0270631851832044, 0.7800504550691978] with appx accuracy of 0.44\n",
      "90. User: 416 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 1.00\n",
      "91. User: 421 weights are: [0.6415416517847025, 0.6382971746813249, 1.0711157263507884, 0.9560872450701314, 0.8844801318894199] with appx accuracy of 0.33\n",
      "92. User: 428 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.44\n",
      "93. User: 431 weights are: [1.098185146971272, 0.5078966401028921, 1.0427564661180257, 1.05532271121278, 0.8715621788569624] with appx accuracy of 0.11\n",
      "94. User: 440 weights are: [0.9219820711724368, 0.9503495768340731, 1.0896290335147492, 1.0827173021951393, 0.812863511068322] with appx accuracy of 0.22\n",
      "95. User: 442 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.33\n",
      "96. User: 443 weights are: [0.5011755180603727, 0.7596455213867905, 1.0745218131731256, 1.0525824595411546, 0.7052568040403729] with appx accuracy of 0.33\n",
      "97. User: 446 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.44\n",
      "98. User: 447 weights are: [0.6691426121972595, 0.8263729392568, 1.0976472313745442, 0.9690412786869096, 1.0196008199789954] with appx accuracy of 1.00\n",
      "99. User: 455 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.33\n",
      "100. User: 459 weights are: [0.6415416517847025, 0.6382971746813249, 1.0711157263507884, 0.9560872450701314, 0.8844801318894199] with appx accuracy of 0.67\n",
      "101. User: 478 weights are: [0.9315976501004086, 0.5485155292161954, 1.0033713131388757, 1.0900646825680318, 0.5078049429136513] with appx accuracy of 0.33\n",
      "102. User: 481 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.33\n",
      "103. User: 492 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.56\n",
      "104. User: 493 weights are: [0.7429436151974546, 1.083419438704004, 1.0226517559271113, 0.9962062597118106, 0.856290212429184] with appx accuracy of 0.22\n",
      "105. User: 497 weights are: [0.5011755180603727, 0.7596455213867905, 1.0745218131731256, 1.0525824595411546, 0.7052568040403729] with appx accuracy of 0.78\n",
      "106. User: 504 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.11\n",
      "107. User: 510 weights are: [0.9315976501004086, 0.5485155292161954, 1.0033713131388757, 1.0900646825680318, 0.5078049429136513] with appx accuracy of 0.33\n",
      "108. User: 512 weights are: [0.6691426121972595, 0.8263729392568, 1.0976472313745442, 0.9690412786869096, 1.0196008199789954] with appx accuracy of 0.11\n",
      "109. User: 523 weights are: [0.5028955462924545, 1.0624624830180456, 1.0210459640526905, 1.0471168441510414, 0.8187040473530225] with appx accuracy of 0.11\n",
      "110. User: 526 weights are: [0.6691426121972595, 0.8263729392568, 1.0976472313745442, 0.9690412786869096, 1.0196008199789954] with appx accuracy of 0.44\n",
      "111. User: 530 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.22\n",
      "112. User: 532 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.11\n",
      "113. User: 535 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.56\n",
      "114. User: 537 weights are: [1.0927615892382787, 0.9866030365573971, 1.088038188031105, 1.0570913251024208, 0.7790453430245213] with appx accuracy of 0.44\n",
      "115. User: 542 weights are: [0.5011755180603727, 0.7596455213867905, 1.0745218131731256, 1.0525824595411546, 0.7052568040403729] with appx accuracy of 0.44\n",
      "116. User: 543 weights are: [0.6415416517847025, 0.6382971746813249, 1.0711157263507884, 0.9560872450701314, 0.8844801318894199] with appx accuracy of 0.33\n",
      "117. User: 546 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.33\n",
      "118. User: 549 weights are: [0.6431838134917369, 0.5048950689080016, 1.0420781157197352, 1.0038795953435442, 0.7384801221042667] with appx accuracy of 0.33\n",
      "119. User: 559 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.22\n",
      "120. User: 564 weights are: [0.8575580555298323, 0.5375308146200483, 1.0325520354341866, 1.0220653143637466, 0.6076774882781608] with appx accuracy of 0.33\n",
      "121. User: 566 weights are: [0.5539699050937379, 0.7595239932619686, 1.0934626762722184, 1.0415095936498207, 0.5508829672179234] with appx accuracy of 0.33\n",
      "122. User: 569 weights are: [1.07494091505811, 0.5226021675021254, 1.0622672708796093, 1.0605946175291803, 0.7537627452098997] with appx accuracy of 0.44\n",
      "123. User: 572 weights are: [1.0835360415809743, 0.8354913993987441, 1.0198712331878548, 1.035192222136227, 0.936233911032374] with appx accuracy of 0.22\n",
      "124. User: 575 weights are: [0.9172158194125173, 0.5141371609235126, 1.0064328923863972, 1.0358113399476407, 0.7989216650451354] with appx accuracy of 0.67\n",
      "125. User: 578 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.33\n",
      "126. User: 587 weights are: [0.6415416517847025, 0.6382971746813249, 1.0711157263507884, 0.9560872450701314, 0.8844801318894199] with appx accuracy of 0.11\n",
      "127. User: 588 weights are: [0.7309125186859506, 0.501475401007075, 1.0725345882838357, 1.0681284358550698, 0.5242808529647488] with appx accuracy of 0.22\n",
      "128. User: 589 weights are: [0.6415416517847025, 0.6382971746813249, 1.0711157263507884, 0.9560872450701314, 0.8844801318894199] with appx accuracy of 0.22\n",
      "129. User: 597 weights are: [0.9866055979624127, 0.821390870053259, 1.0893350144982081, 0.9576474692161194, 0.8910579250019643] with appx accuracy of 0.33\n",
      "130. User: 606 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.33\n",
      "131. User: 608 weights are: [0.9315976501004086, 0.5485155292161954, 1.0033713131388757, 1.0900646825680318, 0.5078049429136513] with appx accuracy of 0.33\n",
      "132. User: 624 weights are: [0.6691426121972595, 0.8263729392568, 1.0976472313745442, 0.9690412786869096, 1.0196008199789954] with appx accuracy of 0.33\n",
      "133. User: 639 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.11\n",
      "134. User: 647 weights are: [0.8781497697364558, 0.5164844058332444, 1.009636271736329, 0.9751055070749608, 0.9022388585794312] with appx accuracy of 0.11\n",
      "135. User: 649 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.22\n",
      "136. User: 656 weights are: [0.6415416517847025, 0.6382971746813249, 1.0711157263507884, 0.9560872450701314, 0.8844801318894199] with appx accuracy of 0.67\n",
      "137. User: 666 weights are: [0.8646933484004478, 1.081397455083117, 1.0930596708782543, 1.038275953019249, 1.0521528534604674] with appx accuracy of 0.78\n",
      "138. User: 673 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 1.00\n",
      "139. User: 674 weights are: [0.7957896501869377, 0.8947686028142405, 1.0170234875971746, 1.0360887737776574, 0.6952723658409126] with appx accuracy of 0.33\n",
      "140. User: 692 weights are: [0.8646933484004478, 1.081397455083117, 1.0930596708782543, 1.038275953019249, 1.0521528534604674] with appx accuracy of 0.33\n",
      "141. User: 701 weights are: [0.8729297191323443, 0.9522857769513937, 1.041023810723141, 0.9726753165162894, 0.8876427606071381] with appx accuracy of 0.11\n",
      "142. User: 702 weights are: [0.9465559570715218, 0.5214326564009029, 1.0182431963284528, 1.0555599764908101, 0.6670958992134507] with appx accuracy of 0.33\n",
      "143. User: 705 weights are: [0.6415416517847025, 0.6382971746813249, 1.0711157263507884, 0.9560872450701314, 0.8844801318894199] with appx accuracy of 0.44\n",
      "144. User: 706 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.44\n",
      "145. User: 708 weights are: [0.8222308964076379, 0.5133440695236455, 1.0305690214428158, 1.0482483071544662, 1.0474499283058492] with appx accuracy of 0.22\n",
      "146. User: 712 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.33\n",
      "147. User: 717 weights are: [0.5004482255847491, 0.5593566436973372, 1.0285720454484484, 1.0270631851832044, 0.7800504550691978] with appx accuracy of 0.44\n",
      "148. User: 721 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.89\n",
      "149. User: 733 weights are: [0.5028955462924545, 1.0624624830180456, 1.0210459640526905, 1.0471168441510414, 0.8187040473530225] with appx accuracy of 0.33\n",
      "150. User: 734 weights are: [0.9315976501004086, 0.5485155292161954, 1.0033713131388757, 1.0900646825680318, 0.5078049429136513] with appx accuracy of 0.44\n",
      "151. User: 739 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.44\n",
      "152. User: 745 weights are: [1.098185146971272, 0.5078966401028921, 1.0427564661180257, 1.05532271121278, 0.8715621788569624] with appx accuracy of 0.33\n",
      "153. User: 746 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.33\n",
      "154. User: 748 weights are: [0.5539699050937379, 0.7595239932619686, 1.0934626762722184, 1.0415095936498207, 0.5508829672179234] with appx accuracy of 0.33\n",
      "155. User: 751 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.44\n",
      "156. User: 769 weights are: [0.5004482255847491, 0.5593566436973372, 1.0285720454484484, 1.0270631851832044, 0.7800504550691978] with appx accuracy of 0.44\n",
      "157. User: 774 weights are: [0.7102806839095057, 0.6305263516230647, 1.060181947207255, 1.091779383271804, 0.6788749176966138] with appx accuracy of 0.22\n",
      "158. User: 779 weights are: [1.0643049885274403, 0.5727147218047988, 1.0674307555964493, 1.0790417212099985, 1.0665195983007454] with appx accuracy of 0.33\n",
      "159. User: 794 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.22\n",
      "160. User: 817 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.22\n",
      "161. User: 820 weights are: [0.8729297191323443, 0.9522857769513937, 1.041023810723141, 0.9726753165162894, 0.8876427606071381] with appx accuracy of 0.44\n",
      "162. User: 824 weights are: [0.6415416517847025, 0.6382971746813249, 1.0711157263507884, 0.9560872450701314, 0.8844801318894199] with appx accuracy of 0.22\n",
      "163. User: 829 weights are: [0.8473264616587173, 1.0019951001263538, 1.0411707095092373, 1.0929873771653644, 0.6622237626119192] with appx accuracy of 0.44\n",
      "164. User: 841 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.56\n",
      "165. User: 845 weights are: [0.8646933484004478, 1.081397455083117, 1.0930596708782543, 1.038275953019249, 1.0521528534604674] with appx accuracy of 0.78\n",
      "166. User: 846 weights are: [0.8646933484004478, 1.081397455083117, 1.0930596708782543, 1.038275953019249, 1.0521528534604674] with appx accuracy of 0.33\n",
      "167. User: 877 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.67\n",
      "168. User: 891 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.89\n",
      "169. User: 899 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.44\n",
      "170. User: 900 weights are: [0.6691426121972595, 0.8263729392568, 1.0976472313745442, 0.9690412786869096, 1.0196008199789954] with appx accuracy of 0.11\n",
      "171. User: 903 weights are: [0.6415416517847025, 0.6382971746813249, 1.0711157263507884, 0.9560872450701314, 0.8844801318894199] with appx accuracy of 0.22\n",
      "172. User: 904 weights are: [0.6250582988321306, 0.6956520216915159, 1.062947009853409, 1.0898434478024952, 0.5606912576191335] with appx accuracy of 0.22\n",
      "173. User: 911 weights are: [0.5011755180603727, 0.7596455213867905, 1.0745218131731256, 1.0525824595411546, 0.7052568040403729] with appx accuracy of 0.67\n",
      "174. User: 913 weights are: [0.9315976501004086, 0.5485155292161954, 1.0033713131388757, 1.0900646825680318, 0.5078049429136513] with appx accuracy of 0.44\n",
      "175. User: 919 weights are: [0.9315976501004086, 0.5485155292161954, 1.0033713131388757, 1.0900646825680318, 0.5078049429136513] with appx accuracy of 0.33\n",
      "176. User: 922 weights are: [0.6058883947918696, 0.8688165506759065, 1.020134584493959, 1.029561942533347, 0.6309566928026664] with appx accuracy of 0.56\n",
      "177. User: 937 weights are: [0.6691426121972595, 0.8263729392568, 1.0976472313745442, 0.9690412786869096, 1.0196008199789954] with appx accuracy of 0.33\n",
      "178. User: 955 weights are: [0.5028955462924545, 1.0624624830180456, 1.0210459640526905, 1.0471168441510414, 0.8187040473530225] with appx accuracy of 0.44\n",
      "179. User: 960 weights are: [0.5423333591915144, 1.0766558074582084, 1.0864759015103291, 1.0216996702630907, 0.5595769025520354] with appx accuracy of 0.44\n",
      "180. User: 963 weights are: [0.5719414079607827, 0.8401704275273028, 1.0348909249880434, 1.0465895956771072, 0.9536418376673024] with appx accuracy of 0.22\n"
     ]
    }
   ],
   "source": [
    "NUM_OF_CROSS_VALIDATION = 3\n",
    "NUM_OF_TRAINED_USERS = len(user_rating)\n",
    "\n",
    "list_best_weights_out: list = []\n",
    "\n",
    "for user in range(NUM_OF_TRAINED_USERS):\n",
    "\n",
    "    accuracy = 0\n",
    "    best_k_out = 0\n",
    "    best_weights_out = [1.1,1.1,1.1,1.1,1.1]\n",
    "\n",
    "    for validation_id in range(NUM_OF_CROSS_VALIDATION):\n",
    "\n",
    "        keys = list(user_rating['RATED'][user].keys())\n",
    "        random.shuffle(keys)\n",
    "        split_index = int(len(keys) * 0.9)\n",
    "        train_valid_keys = keys[:split_index]\n",
    "        test_keys = keys[split_index:]\n",
    "\n",
    "        keys = list(train_valid_keys)\n",
    "        random.shuffle(keys)\n",
    "        split_index = int(len(keys) * 0.85)\n",
    "        train_keys = keys[:split_index]\n",
    "        valid_keys = keys[split_index:]\n",
    "\n",
    "\n",
    "        test_ids = [int(key) for key in test_keys]\n",
    "        validate_ids = [int(key) for key in valid_keys]\n",
    "        training_ids = [int(key) for key in train_keys]\n",
    "\n",
    "        # print(f'Train keys: {train_keys}\\nValid keys: {valid_keys}\\nTest keys: {test_keys}')\n",
    "\n",
    "        _, temp_best_weights_out = optimize_user(user, validate_ids, training_ids)\n",
    "\n",
    "        temp_accuracy = test_user(user_id=user, best_weights=temp_best_weights_out, test_ids=test_ids, train_ids=train_valid_keys)\n",
    "\n",
    "        if temp_accuracy > accuracy:\n",
    "            accuracy = temp_accuracy\n",
    "            best_weights_out = temp_best_weights_out\n",
    "        \n",
    "    print(f\"{user}. User: {user_rating['USER_ID'][user]} weights are: {best_weights_out} with appx accuracy of {accuracy:.2f}\") if accuracy is not 0 else print(f\"{user}. {user_rating['USER_ID'][user]} has accuracy of 0!\")\n",
    "    list_best_weights_out.append(best_weights_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_test_data = {\n",
    "    user_rating['USER_ID'][i]: list_best_weights_out[i] for i in range(NUM_OF_TRAINED_USERS)\n",
    "}\n",
    "user_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_test_data_df = pd.DataFrame(user_test_data)\n",
    "user_test_data_df.to_json(JSON_PATH + '\\\\USER_HYPER_PARAMS_old.json', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_test_data = {\n",
    "    str(user_rating['USER_ID'][i]): list_best_weights_out[i]\n",
    "    for i in range(NUM_OF_TRAINED_USERS)\n",
    "}\n",
    "\n",
    "import json\n",
    "\n",
    "with open(JSON_PATH + r'\\USER_HYPER_PARAMS.json', 'w') as f:\n",
    "    json.dump(user_test_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output = decision_tree(movie_id=2, all_distances=movie_distance, rating_data=user_rating.loc[user_rating[\"USER_ID\"] == 5, \"RATED\"][0], threshold=[0.7, 0.7, 2, 2, 0.7])\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
