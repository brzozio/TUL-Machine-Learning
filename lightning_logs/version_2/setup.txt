  | Name      | Type             | Params | Mode
-------------------------------------------------------
0 | embedding | Embedding        | 2.2 K  | train
1 | lstm      | LSTM             | 8.4 K  | train
2 | linear    | Linear           | 2.3 K  | train
3 | loss_fn   | CrossEntropyLoss | 0      | train
-------------------------------------------------------

ilość tokenów w kontekście:     128
rozmiar ukrytej warstwy LSTM:   32
ilość warstw LSTM:      1

początkowy kontekst:"N"
"Nie strasznym dubo
I przysię djązefrać słojny ledzić
Krzyciość Naprak Niejbykiwała
Szyntki zegola bła"

początkowy kontekst:"M"
"Mo
Tadeusza się oczy Wielał Skojunęta Proczet jtoni i na wielnie lepił w stalijej o znawieni szlaż zd"

początkowy kontekst:"Litwo"
"Litwotwa grogo postropani przy zdoburzyś domuby polęcykiew stały
Zgadka w trzeburów co zagrołocko Dobrzy "

początkowy kontekst:"Bigos"
"Bigostu i cosina
Muszy się bliska  marem
Jecej że  z jestem
Dój kaciem widzi zmieciem  zakrodzie
Rzieci d"